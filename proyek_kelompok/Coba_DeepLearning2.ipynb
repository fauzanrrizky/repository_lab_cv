{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import torch\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Learning (Siamese Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path ke video dan gambar target\n",
    "# video_path = os.path.join('repository_lab_cv', 'proyek_kelompok', 'assets', 'test_video', 'OTV3.mp4')\n",
    "template_path = os.path.join('assets', 'dataset', 'Mario-Target.png')\n",
    "template_image = cv2.imread(template_path)\n",
    "template_image = cv2.resize(template_image, (64, 64))  # Resize ke ukuran tetap\n",
    "\n",
    "output_path = 'mario_detection_orb.mp4'  # Path untuk menyimpan video hasil\n",
    "\n",
    "# Augmentasi data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate augmented images\n",
    "template_image = np.expand_dims(template_image, axis=0)\n",
    "augmented_images = datagen.flow(template_image, batch_size=1)\n",
    "\n",
    "for i in range(10):  # Simpan 10 augmented images\n",
    "    aug_image = next(augmented_images)[0].astype('uint8')\n",
    "    cv2.imwrite(f'augmented_data/augmented_mario_{i}.png', aug_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_network(input_shape):\n",
    "    # Load pretrained MobileNetV2 model\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Add global average pooling and dense layer for feature extraction\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='sigmoid')(x)  # Feature embedding layer\n",
    "\n",
    "    model = Model(base_model.input, x, name='MobileNetV2_Siamese')\n",
    "    return model\n",
    "\n",
    "# Input size\n",
    "input_shape = (64, 64, 3)  # Ensure your dataset matches this size\n",
    "\n",
    "# Create Siamese branches\n",
    "siamese_base = build_siamese_network(input_shape)\n",
    "\n",
    "# Define inputs\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# Extract features using MobileNetV2\n",
    "feature_a = siamese_base(input_a)\n",
    "feature_b = siamese_base(input_b)\n",
    "\n",
    "# Compute L1 distance between feature vectors\n",
    "l1_distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([feature_a, feature_b])\n",
    "\n",
    "# Output layer (similarity score)\n",
    "output = Dense(1, activation='sigmoid')(l1_distance)\n",
    "\n",
    "# Build and compile Siamese model\n",
    "siamese_model = Model([input_a, input_b], output)\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_images_from_directory(directory, label, target_size=(64, 64)):\n",
    "    \"\"\"Load images from a given directory and assign a label.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".png\"):\n",
    "            img_path = os.path.join(directory, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, target_size)  # Resize to target size\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load Mario images\n",
    "mario_directory = \"./augmented_data\"\n",
    "mario_images, mario_labels = load_images_from_directory(mario_directory, label=1)  # Label 1 for Mario\n",
    "\n",
    "# Load CIFAR-10 data using DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize CIFAR images to match Mario image size\n",
    "    transforms.ToTensor(),       # Convert to Tensor\n",
    "])\n",
    "\n",
    "cifar10_data = datasets.CIFAR10(root='./cifar', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(cifar10_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# Limit CIFAR images to match the number of Mario images\n",
    "cifar_images = []\n",
    "cifar_labels = []\n",
    "num_mario_images = len(mario_images)  # Limit CIFAR images to this number\n",
    "\n",
    "for idx, (img, label) in enumerate(dataloader):\n",
    "    if idx >= num_mario_images:\n",
    "        break\n",
    "    img_np = img.squeeze(0).permute(1, 2, 0).numpy()  # Convert Tensor to numpy array\n",
    "    cifar_images.append((img_np * 255).astype(np.uint8))  # Convert to uint8 format\n",
    "    cifar_labels.append(0)  # Assign label 0 for non-Mario\n",
    "\n",
    "# Convert CIFAR images and labels to numpy arrays\n",
    "cifar_images = np.array(cifar_images)\n",
    "cifar_labels = np.array(cifar_labels)\n",
    "\n",
    "# Combine Mario and CIFAR datasets\n",
    "data = np.concatenate((mario_images, cifar_images), axis=0)\n",
    "labels = np.concatenate((mario_labels, cifar_labels), axis=0)\n",
    "\n",
    "# Shuffle the dataset\n",
    "indices = np.arange(len(data))\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Create pairs for Siamese training\n",
    "def create_pairs(data, labels):\n",
    "    \"\"\"Create positive and negative pairs for training.\"\"\"\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "\n",
    "    # Create positive pairs\n",
    "    mario_indices = np.where(labels == 1)[0]\n",
    "    for i in range(len(mario_indices)):\n",
    "        for j in range(i + 1, len(mario_indices)):\n",
    "            pairs.append([data[mario_indices[i]], data[mario_indices[j]]])\n",
    "            pair_labels.append(1)\n",
    "\n",
    "    # Create negative pairs\n",
    "    non_mario_indices = np.where(labels == 0)[0]\n",
    "    for i in mario_indices:\n",
    "        for j in non_mario_indices:\n",
    "            pairs.append([data[i], data[j]])\n",
    "            pair_labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(pair_labels)\n",
    "\n",
    "# Generate pairs\n",
    "pairs, pair_labels = create_pairs(data, labels)\n",
    "\n",
    "# Normalize data\n",
    "pairs = pairs / 255.0  # Normalize images to [0, 1] range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat folder untuk menyimpan model jika belum ada\n",
    "model_folder = \"./model\"\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "\n",
    "# Split data menjadi training dan validation\n",
    "pairs_train, pairs_val, labels_train, labels_val = train_test_split(\n",
    "    pairs, pair_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Extract inputs (pair components) from the training and validation pairs\n",
    "train_input_a = pairs_train[:, 0]\n",
    "train_input_b = pairs_train[:, 1]\n",
    "val_input_a = pairs_val[:, 0]\n",
    "val_input_b = pairs_val[:, 1]\n",
    "\n",
    "# Simpan model terbaik berdasarkan validation accuracy\n",
    "checkpoint_path = os.path.join(model_folder, \"siamese_best_model.h5\")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = siamese_model.fit(\n",
    "    [train_input_a, train_input_b], labels_train,\n",
    "    validation_data=([val_input_a, val_input_b], labels_val),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Save final model and weights separately\n",
    "final_model_path = os.path.join(model_folder, \"siamese_final_model.h5\")\n",
    "weights_path = os.path.join(model_folder, \"siamese_final_weights.h5\")\n",
    "\n",
    "# Save the full model (architecture + weights)\n",
    "siamese_model.save(final_model_path)\n",
    "\n",
    "# Save only the weights\n",
    "siamese_model.save_weights(weights_path)\n",
    "print(f\"Model and weights saved to {model_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model\n",
    "final_model = load_model(\"./model/siamese_final_model.h5\")\n",
    "\n",
    "# Load weights\n",
    "final_model.load_weights(\"./model/siamese_final_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Windows: 100%|██████████| 2162/2162 [02:11<00:00, 16.45window/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved Siamese model\n",
    "model_path = \"./model/siamese_best_model.h5\"\n",
    "siamese_model = load_model(model_path)\n",
    "\n",
    "# Preprocess image\n",
    "def preprocess_image(image, target_size):\n",
    "    \"\"\"Resize and normalize image for inference.\"\"\"\n",
    "    img = cv2.resize(image, target_size)\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Sliding window function with scaling\n",
    "def sliding_window_multi_scale(image, scales, stride):\n",
    "    \"\"\"Slide windows across the image at multiple scales.\"\"\"\n",
    "    windows = []\n",
    "    coords = []\n",
    "    for scale in scales:\n",
    "        scaled_window_size = (int(64 * scale), int(64 * scale))\n",
    "        for y in range(0, image.shape[0] - scaled_window_size[1] + 1, stride):\n",
    "            for x in range(0, image.shape[1] - scaled_window_size[0] + 1, stride):\n",
    "                window = image[y:y + scaled_window_size[1], x:x + scaled_window_size[0]]\n",
    "                if window.shape[:2] == scaled_window_size:  # Ensure window size matches\n",
    "                    windows.append((window, (x, y, scaled_window_size[0], scaled_window_size[1])))\n",
    "    return windows\n",
    "\n",
    "# Load the reference template (Mario template)\n",
    "reference_template_path = \"./augmented_data/augmented_mario_0.png\"  # Example template\n",
    "reference_image = cv2.imread(reference_template_path)\n",
    "\n",
    "# Preprocess reference image\n",
    "reference_image_preprocessed = preprocess_image(reference_image, (64, 64))\n",
    "\n",
    "# Load target image (image to search Mario in)\n",
    "target_image_path = \"./assets/dataset/video.PNG\"  # Replace with your test image\n",
    "target_image = cv2.imread(target_image_path)\n",
    "\n",
    "# Sliding window parameters\n",
    "scales = [0.5, 1.0, 1.5]  # Multi-scale factors (smaller, original, larger)\n",
    "stride = 32  # Step size for sliding window\n",
    "threshold = 0.4  # Similarity threshold to classify as Mario\n",
    "\n",
    "# Perform sliding window across multiple scales\n",
    "windows = sliding_window_multi_scale(target_image, scales, stride)\n",
    "\n",
    "# Initialize progress bar and detected boxes\n",
    "detected_boxes = []\n",
    "with tqdm(total=len(windows), desc=\"Processing Windows\", unit=\"window\") as pbar:\n",
    "    for window, (x, y, w, h) in windows:\n",
    "        # Preprocess window\n",
    "        window_preprocessed = preprocess_image(window, (64, 64))\n",
    "        \n",
    "        # Predict similarity using Siamese Network\n",
    "        similarity = siamese_model.predict([reference_image_preprocessed, window_preprocessed], verbose=0)[0][0]\n",
    "        \n",
    "        # If similarity exceeds threshold, save the bounding box\n",
    "        if similarity > threshold:\n",
    "            detected_boxes.append((x, y, x + w, y + h))\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# Apply Non-Maximum Suppression (NMS) to combine overlapping boxes\n",
    "def non_maximum_suppression(boxes, overlap_thresh=0.5):\n",
    "    \"\"\"Apply NMS to reduce overlapping bounding boxes.\"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # Convert boxes to array format\n",
    "    boxes = np.array(boxes)\n",
    "    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "\n",
    "    # Compute area of each box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    indices = np.argsort(y2)\n",
    "\n",
    "    selected_boxes = []\n",
    "    while len(indices) > 0:\n",
    "        last = len(indices) - 1\n",
    "        i = indices[last]\n",
    "        selected_boxes.append(i)\n",
    "\n",
    "        # Compute overlap\n",
    "        xx1 = np.maximum(x1[i], x1[indices[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[indices[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[indices[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[indices[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        overlap = (w * h) / area[indices[:last]]\n",
    "\n",
    "        # Keep boxes with overlap less than the threshold\n",
    "        indices = np.delete(indices, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))\n",
    "\n",
    "    return boxes[selected_boxes].astype(int)\n",
    "\n",
    "# Apply NMS\n",
    "final_boxes = non_maximum_suppression(detected_boxes)\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "for (x1, y1, x2, y2) in final_boxes:\n",
    "    cv2.rectangle(target_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow(\"Mario Detection\", target_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
