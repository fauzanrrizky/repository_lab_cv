{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CKchdxcpRbUF"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6zM9P_NSAGr"
   },
   "source": [
    "# One shot learning (Siamese or prototype) network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4sT3xY9SFIZ"
   },
   "source": [
    "## Augmentasi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2JXS2dvFTbhE"
   },
   "outputs": [],
   "source": [
    "# Path ke video dan gambar target\n",
    "# video_path = os.path.join('repository_lab_cv', 'proyek_kelompok', 'assets', 'test_video', 'OTV3.mp4')\n",
    "template_path = os.path.join('assets', 'dataset', 'Mario-Target.png')\n",
    "template_image = cv2.imread(template_path)\n",
    "template_image = cv2.resize(template_image, (64, 64))  # Resize ke ukuran tetap\n",
    "\n",
    "output_path = 'mario_detection_orb.mp4'  # Path untuk menyimpan video hasil\n",
    "\n",
    "# Augmentasi data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate augmented images\n",
    "template_image = np.expand_dims(template_image, axis=0)\n",
    "augmented_images = datagen.flow(template_image, batch_size=1)\n",
    "\n",
    "for i in range(5):  # Simpan 5 augmented images\n",
    "    aug_image = next(augmented_images)[0].astype('uint8')\n",
    "    cv2.imwrite(f'augmented_data/augmented_mario_{i}.png', aug_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NgUqKKiAT-Lb"
   },
   "outputs": [],
   "source": [
    "def build_siamese_network(input_shape):\n",
    "    # Arsitektur CNN untuk ekstraksi fitur\n",
    "    input = Input(input_shape)\n",
    "    x = Conv2D(64, (7, 7), activation='relu')(input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='sigmoid')(x)\n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "# Input size\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "# Create Siamese branches\n",
    "siamese_base = build_siamese_network(input_shape)\n",
    "\n",
    "# Define inputs\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# Extract features\n",
    "feature_a = siamese_base(input_a)\n",
    "feature_b = siamese_base(input_b)\n",
    "\n",
    "# Compute L1 distance\n",
    "l1_distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([feature_a, feature_b])\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(l1_distance)\n",
    "\n",
    "# Siamese model\n",
    "siamese_model = Model([input_a, input_b], output)\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5Kus2R-2Ur_f"
   },
   "outputs": [],
   "source": [
    "def create_pairs(positive_images, negative_images):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Positive pairs\n",
    "    for i in range(len(positive_images)):\n",
    "        for j in range(i + 1, len(positive_images)):\n",
    "            pairs.append([positive_images[i], positive_images[j]])\n",
    "            labels.append(1)\n",
    "\n",
    "    # Negative pairs\n",
    "    for i in range(len(positive_images)):\n",
    "        for j in range(len(negative_images)):\n",
    "            pairs.append([positive_images[i], negative_images[j]])\n",
    "            labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vkoAz_RQVfZu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Loop ke: \n",
      "0\n",
      "Loop ke: \n",
      "1\n",
      "Loop ke: \n",
      "2\n",
      "Loop ke: \n",
      "3\n",
      "Loop ke: \n",
      "4\n",
      "Loop ke: \n",
      "5\n",
      "Loop ke: \n",
      "6\n",
      "Loop ke: \n",
      "7\n",
      "Loop ke: \n",
      "8\n",
      "Loop ke: \n",
      "9\n",
      "Loop ke: \n",
      "10\n",
      "Loop ke: \n",
      "11\n",
      "Loop ke: \n",
      "12\n",
      "Loop ke: \n",
      "13\n",
      "Loop ke: \n",
      "14\n",
      "Loop ke: \n",
      "15\n",
      "Loop ke: \n",
      "16\n",
      "Loop ke: \n",
      "17\n",
      "Loop ke: \n",
      "18\n",
      "Loop ke: \n",
      "19\n",
      "Loop ke: \n",
      "20\n",
      "Loop ke: \n",
      "21\n",
      "Loop ke: \n",
      "22\n",
      "Loop ke: \n",
      "23\n",
      "Loop ke: \n",
      "24\n",
      "Loop ke: \n",
      "25\n",
      "Loop ke: \n",
      "26\n",
      "Loop ke: \n",
      "27\n",
      "Loop ke: \n",
      "28\n",
      "Loop ke: \n",
      "29\n",
      "Loop ke: \n",
      "30\n",
      "Loop ke: \n",
      "31\n",
      "Loop ke: \n",
      "32\n",
      "Loop ke: \n",
      "33\n",
      "Loop ke: \n",
      "34\n",
      "Loop ke: \n",
      "35\n",
      "Loop ke: \n",
      "36\n",
      "Loop ke: \n",
      "37\n",
      "Loop ke: \n",
      "38\n",
      "Loop ke: \n",
      "39\n",
      "Loop ke: \n",
      "40\n",
      "Loop ke: \n",
      "41\n",
      "Loop ke: \n",
      "42\n",
      "Loop ke: \n",
      "43\n",
      "Loop ke: \n",
      "44\n",
      "Loop ke: \n",
      "45\n",
      "Loop ke: \n",
      "46\n",
      "Loop ke: \n",
      "47\n",
      "Loop ke: \n",
      "48\n",
      "Loop ke: \n",
      "49\n",
      "Loop ke: \n",
      "50\n",
      "Loop ke: \n",
      "51\n",
      "Loop ke: \n",
      "52\n",
      "Loop ke: \n",
      "53\n",
      "Loop ke: \n",
      "54\n",
      "Loop ke: \n",
      "55\n",
      "Loop ke: \n",
      "56\n",
      "Loop ke: \n",
      "57\n",
      "Loop ke: \n",
      "58\n",
      "Loop ke: \n",
      "59\n",
      "Loop ke: \n",
      "60\n",
      "Loop ke: \n",
      "61\n",
      "Loop ke: \n",
      "62\n",
      "Loop ke: \n",
      "63\n",
      "Loop ke: \n",
      "64\n",
      "Loop ke: \n",
      "65\n",
      "Loop ke: \n",
      "66\n",
      "Loop ke: \n",
      "67\n",
      "Loop ke: \n",
      "68\n",
      "Loop ke: \n",
      "69\n",
      "Loop ke: \n",
      "70\n",
      "Loop ke: \n",
      "71\n",
      "Loop ke: \n",
      "72\n",
      "Loop ke: \n",
      "73\n",
      "Loop ke: \n",
      "74\n",
      "Loop ke: \n",
      "75\n",
      "Loop ke: \n",
      "76\n",
      "Loop ke: \n",
      "77\n",
      "Loop ke: \n",
      "78\n",
      "Loop ke: \n",
      "79\n",
      "Loop ke: \n",
      "80\n",
      "Loop ke: \n",
      "81\n",
      "Loop ke: \n",
      "82\n",
      "Loop ke: \n",
      "83\n",
      "Loop ke: \n",
      "84\n",
      "Loop ke: \n",
      "85\n",
      "Loop ke: \n",
      "86\n",
      "Loop ke: \n",
      "87\n",
      "Loop ke: \n",
      "88\n",
      "Loop ke: \n",
      "89\n",
      "Loop ke: \n",
      "90\n",
      "Loop ke: \n",
      "91\n",
      "Loop ke: \n",
      "92\n",
      "Loop ke: \n",
      "93\n",
      "Loop ke: \n",
      "94\n",
      "Loop ke: \n",
      "95\n",
      "Loop ke: \n",
      "96\n",
      "Loop ke: \n",
      "97\n",
      "Loop ke: \n",
      "98\n",
      "Loop ke: \n",
      "99\n",
      "Loaded 100 negative images.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Transformasi untuk dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize gambar ke 64x64\n",
    "    transforms.ToTensor()  # Konversi ke tensor\n",
    "])\n",
    "\n",
    "# Unduh CIFAR-10 dataset\n",
    "cifar10_data = datasets.CIFAR10(root='cifar', train=True, transform=transform, download=True)\n",
    "\n",
    "# Inisialisasi DataLoader\n",
    "dataloader = DataLoader(cifar10_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load beberapa gambar negatif\n",
    "negative_images = []\n",
    "for i, (image, label) in enumerate(dataloader):\n",
    "    if i >= 100:  # Ambil 100 gambar negatif\n",
    "        break\n",
    "    # Konversi tensor ke numpy (untuk OpenCV)\n",
    "    img = image[0].permute(1, 2, 0).numpy() * 255  # Permute dimensi untuk OpenCV\n",
    "    img = img.astype(np.uint8)  # Pastikan format uint8\n",
    "    negative_images.append(img)\n",
    "    print(\"Loop ke: \")\n",
    "    print(i)\n",
    "\n",
    "negative_images = np.array(negative_images)\n",
    "\n",
    "# Verifikasi hasil\n",
    "print(f\"Loaded {len(negative_images)} negative images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tec7kFbBVsv6"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path ke direktori gambar augmented Mario\n",
    "positive_folder = './augmented_data'  # Folder root (di mana augmented_mario_X.png berada)\n",
    "\n",
    "# Load semua gambar augmented Mario\n",
    "positive_images = []\n",
    "for filename in sorted(os.listdir(positive_folder)):  # Pastikan file terurut\n",
    "    if filename.startswith('augmented_mario') and filename.endswith('.png'):  # Filter nama file\n",
    "        img_path = os.path.join(positive_folder, filename)\n",
    "        img = cv2.imread(img_path)  # Baca gambar\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Pastikan ukuran sama\n",
    "            positive_images.append(img)\n",
    "\n",
    "positive_images = np.array(positive_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axEwtz2YUzG3",
    "outputId": "778dc261-46f5-4db2-ecb9-ac90cd536414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 7s 99ms/step - loss: 0.7342 - accuracy: 0.3667\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.6855 - accuracy: 0.6059\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.6845 - accuracy: 0.5980\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.6713 - accuracy: 0.5961\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.6596 - accuracy: 0.8922\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.6474 - accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.6354 - accuracy: 0.9804\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.6237 - accuracy: 0.9804\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.6124 - accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.6014 - accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e802681ea0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data (augmented positive samples and negative samples)\n",
    "pairs, labels = create_pairs(positive_images, negative_images)\n",
    "\n",
    "# Train model\n",
    "siamese_model.fit([pairs[:, 0], pairs[:, 1]], labels, batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect in Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template Mario\n",
    "import cv2\n",
    "template_path = './assets/dataset/Mario-Target.png'  # Path ke salah satu gambar Mario\n",
    "template_image = cv2.imread(template_path)\n",
    "template_image = cv2.resize(template_image, (64, 64))  # Pastikan ukuran sesuai dengan training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def non_max_suppression(boxes, scores, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Non-Maximum Suppression untuk menggabungkan bounding box yang tumpang tindih.\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    # Koordinat kotak\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    # Area bounding box\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]  # Urutkan skor secara menurun\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        overlap = (w * h) / areas[order[1:]]\n",
    "\n",
    "        # Hanya pertahankan kotak yang overlap-nya kurang dari threshold\n",
    "        order = order[np.where(overlap <= iou_threshold)[0] + 1]\n",
    "\n",
    "    return boxes[keep].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in_batches(siamese_model, template_input, patches_input, batch_size=32):\n",
    "    \"\"\"\n",
    "    Prediksi batch secara bertahap untuk menghindari kehabisan memori.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in range(0, len(patches_input), batch_size):\n",
    "        batch_patches = patches_input[i:i + batch_size]\n",
    "        batch_templates = np.repeat(template_input, len(batch_patches), axis=0)\n",
    "        batch_scores = siamese_model.predict([batch_templates, batch_patches], verbose=0)\n",
    "        scores.extend(batch_scores)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_mario_in_frame(frame, siamese_model, template_image, threshold=0.7, iou_threshold=0.5):\n",
    "    h, w, _ = frame.shape\n",
    "    patch_size = template_image.shape[:2]\n",
    "    stride = 64  # Langkah sliding window\n",
    "\n",
    "    detected_boxes = []\n",
    "    scores = []\n",
    "    patches = []\n",
    "    coordinates = []\n",
    "\n",
    "    # Sliding window\n",
    "    for y in range(0, h - patch_size[0], stride):\n",
    "        for x in range(0, w - patch_size[1], stride):\n",
    "            patch = frame[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "            patch = cv2.resize(patch, (patch_size[1], patch_size[0]))\n",
    "            patches.append(patch)\n",
    "            coordinates.append((x, y, x + patch_size[1], y + patch_size[0]))\n",
    "\n",
    "    # Preprocess template dan patches\n",
    "    template_input = np.expand_dims(template_image.astype(np.float32) / 255.0, axis=0)\n",
    "    patches_input = np.array(patches).astype(np.float32) / 255.0\n",
    "\n",
    "    # Predict in batches\n",
    "    batch_size = 32\n",
    "    pred_scores = predict_in_batches(siamese_model, template_input, patches_input, batch_size=batch_size)\n",
    "\n",
    "    # Filter berdasarkan threshold\n",
    "    for i, score in enumerate(pred_scores):\n",
    "        if score[0] > threshold:\n",
    "            detected_boxes.append(coordinates[i])\n",
    "            scores.append(score[0])\n",
    "\n",
    "    # Gunakan NMS untuk menggabungkan bounding box\n",
    "    if len(detected_boxes) > 0:\n",
    "        final_boxes = non_max_suppression(detected_boxes, scores, iou_threshold=iou_threshold)\n",
    "    else:\n",
    "        final_boxes = []\n",
    "\n",
    "    return final_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Video: 100%|██████████| 1008/1008 [04:19<00:00,  3.88frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path ke video input dan output\n",
    "video_path = './assets/test_video/OTV1.mp4'\n",
    "output_path = './output_video/test1.mp4'\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Dapatkan properti video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frame dalam video\n",
    "\n",
    "# Video Writer untuk menyimpan hasil\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(total=total_frames, desc=\"Processing Video\", unit=\"frame\")\n",
    "\n",
    "# Proses setiap frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (frame_width // 2, frame_height // 2))\n",
    "\n",
    "    # Deteksi Mario pada frame\n",
    "    boxes = detect_mario_in_frame(frame, siamese_model, template_image, threshold=0.7)\n",
    "\n",
    "    # Gambar bounding box pada frame\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Bounding box hijau\n",
    "\n",
    "    # Simpan frame hasil\n",
    "    out.write(frame)\n",
    "\n",
    "    # Update progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Release resources\n",
    "progress_bar.close()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Video processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image, target_size):\n",
    "    \"\"\"\n",
    "    Preprocess gambar untuk prediksi:\n",
    "    - Resize ke target size.\n",
    "    - Normalisasi pixel value ke [0, 1].\n",
    "    - Tambahkan dimensi batch.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(image, target_size)  # Resize\n",
    "    image = image.astype(np.float32) / 255.0  # Normalisasi\n",
    "    image = np.expand_dims(image, axis=0)  # Tambahkan dimensi batch\n",
    "    return image\n",
    "\n",
    "def predict_similarity(template_path, target_path, siamese_model):\n",
    "    \"\"\"\n",
    "    Prediksi kesamaan antara template dan gambar target.\n",
    "    \"\"\"\n",
    "    # Load template dan gambar target\n",
    "    template_image = cv2.imread(template_path)\n",
    "    target_image = cv2.imread(target_path)\n",
    "\n",
    "    if template_image is None or target_image is None:\n",
    "        print(\"Error: Cannot load one or both images.\")\n",
    "        return\n",
    "\n",
    "    # Preprocess kedua gambar\n",
    "    target_size = (64, 64)  # Sesuaikan dengan input model Anda\n",
    "    template_processed = preprocess_image(template_image, target_size)\n",
    "    target_processed = preprocess_image(target_image, target_size)\n",
    "\n",
    "    # Prediksi kesamaan menggunakan model Siamese\n",
    "    similarity_score = siamese_model.predict([template_processed, target_processed])[0][0]\n",
    "\n",
    "    print(f\"Similarity Score: {similarity_score}\")\n",
    "    return similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n",
      "Similarity Score: 0.4636431932449341\n",
      "Not Mario!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4636432"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_path = './assets/dataset/Mario-Target.PNG'  # Path ke template Mario\n",
    "target_path = './assets/dataset/video.PNG'  # Path ke gambar target\n",
    "\n",
    "# Prediksi kesamaan\n",
    "similarity_score = predict_similarity(template_path, target_path, siamese_model)\n",
    "\n",
    "# Keputusan berdasarkan threshold\n",
    "threshold = 0.7\n",
    "if similarity_score > threshold:\n",
    "    print(\"Mario Detected!\")\n",
    "else:\n",
    "    print(\"Not Mario!\")\n",
    "\n",
    "similarity_score\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "company-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
